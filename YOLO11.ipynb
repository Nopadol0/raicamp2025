{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVsUg43RNlAP"
      },
      "source": [
        "# Setup YOLO11\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49mnaQ9BM5Za",
        "outputId": "05179f38-a918-4310-cdc8-e526dfc9a226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.1/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naw_F252Nr8Q"
      },
      "source": [
        "# 1. Predict ( Test Setup YOLO11)\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf3bol6RNpYv",
        "outputId": "859e848b-f2b6-4e7d-d65e-0956f528487d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 45.4ms\n",
            "Speed: 3.4ms preprocess, 45.4ms inference, 135.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "# Run inference on an image with YOLOv11n\n",
        "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTjwhBCRO3_g"
      },
      "source": [
        "# 2. Add Zip Data Export YOLO11 for Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "d3MBBJ4nO4_G",
        "outputId": "7a20cfaa-f12d-4ef8-84c2-a3197a8897f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6ddb0a0f-6d9a-4b2c-8058-0227b8a479a5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6ddb0a0f-6d9a-4b2c-8058-0227b8a479a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving RAI 2025 Project.v2i.yolov11.zip to RAI 2025 Project.v2i.yolov11 (1).zip\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "%cd /content\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  pass\n",
        "\n",
        "zip_ref = zipfile.ZipFile(filename, 'r')\n",
        "zip_ref.extractall(\"/content/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9o9EVrvO7iQ"
      },
      "source": [
        "# 3. Train Data Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjQXF2dQO7RZ",
        "outputId": "49e546b1-628b-4240-9ec3-f738d28c496a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739604587.506943    5608 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739604587.513263    5608 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100% 22/22 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels.cache... 7 images, 1 backgrounds, 0 corrupt: 100% 7/7 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.35G      1.595      3.322      1.484         15        640: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.72it/s]\n",
            "                   all          7         16    0.00578      0.759     0.0734     0.0461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.38G      1.348      3.393      1.411         13        640: 100% 2/2 [00:00<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.41it/s]\n",
            "                   all          7         16    0.00618      0.759      0.111     0.0688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.35G      1.293      3.213      1.342         30        640: 100% 2/2 [00:00<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.08it/s]\n",
            "                   all          7         16    0.00757       0.88      0.201      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.37G       1.06      3.129      1.193         31        640: 100% 2/2 [00:00<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.02it/s]\n",
            "                   all          7         16    0.00933          1      0.315      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50       2.4G       1.04      2.895      1.128         37        640: 100% 2/2 [00:00<00:00,  4.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.05it/s]\n",
            "                   all          7         16    0.00975          1      0.483      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.39G     0.9912      2.691      1.175         27        640: 100% 2/2 [00:00<00:00,  4.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.48it/s]\n",
            "                   all          7         16    0.00951          1      0.543      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.35G      1.142      2.586      1.238         25        640: 100% 2/2 [00:00<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.84it/s]\n",
            "                   all          7         16    0.00938          1      0.535      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.39G      1.056      2.253      1.223         19        640: 100% 2/2 [00:00<00:00,  4.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.52it/s]\n",
            "                   all          7         16    0.00946          1      0.538      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.39G      1.027      2.115       1.15         38        640: 100% 2/2 [00:00<00:00,  5.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.60it/s]\n",
            "                   all          7         16    0.00924          1       0.56      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.39G      1.022       2.14      1.131         35        640: 100% 2/2 [00:00<00:00,  4.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.96it/s]\n",
            "                   all          7         16    0.00864          1      0.567       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.39G      1.126      1.915      1.248         20        640: 100% 2/2 [00:00<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.28it/s]\n",
            "                   all          7         16    0.00856          1      0.597      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.41G      1.041      1.965      1.149         28        640: 100% 2/2 [00:00<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.21it/s]\n",
            "                   all          7         16    0.00812          1      0.685      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.39G      1.032      1.904      1.152         30        640: 100% 2/2 [00:00<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.19it/s]\n",
            "                   all          7         16    0.00811          1      0.675      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.41G     0.9817      1.632      1.126         20        640: 100% 2/2 [00:00<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.54it/s]\n",
            "                   all          7         16    0.00829          1      0.713      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.39G     0.9826      1.547      1.162         30        640: 100% 2/2 [00:00<00:00,  5.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.82it/s]\n",
            "                   all          7         16    0.00874          1      0.737      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.39G      1.025      1.589      1.214         30        640: 100% 2/2 [00:00<00:00,  4.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.33it/s]\n",
            "                   all          7         16    0.00899          1      0.726      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.39G      1.049       1.37      1.177         24        640: 100% 2/2 [00:00<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.32it/s]\n",
            "                   all          7         16     0.0102          1      0.785      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.39G      0.893      1.382      1.082         41        640: 100% 2/2 [00:00<00:00,  4.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.52it/s]\n",
            "                   all          7         16     0.0101          1      0.796        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.39G     0.9987      1.417      1.181         43        640: 100% 2/2 [00:00<00:00,  5.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.35it/s]\n",
            "                   all          7         16     0.0101          1      0.751      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.39G      1.102      1.427      1.199         36        640: 100% 2/2 [00:00<00:00,  5.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.52it/s]\n",
            "                   all          7         16    0.00981          1        0.8      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.38G      1.071      1.313      1.219         22        640: 100% 2/2 [00:00<00:00,  4.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.86it/s]\n",
            "                   all          7         16    0.00961          1      0.725      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.41G      1.085      1.362      1.126         25        640: 100% 2/2 [00:00<00:00,  4.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.50it/s]\n",
            "                   all          7         16    0.00955          1      0.736      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.41G     0.9799      1.233      1.118         28        640: 100% 2/2 [00:00<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.16it/s]\n",
            "                   all          7         16      0.636      0.685      0.787      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.39G      1.045      1.232      1.131         21        640: 100% 2/2 [00:00<00:00,  5.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.85it/s]\n",
            "                   all          7         16      0.952      0.333      0.788      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.39G      1.028       1.27       1.19         19        640: 100% 2/2 [00:00<00:00,  5.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.41it/s]\n",
            "                   all          7         16      0.936      0.314      0.756      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.38G     0.9635      1.293      1.158         21        640: 100% 2/2 [00:00<00:00,  5.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.06it/s]\n",
            "                   all          7         16      0.933      0.294      0.752       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.41G      1.016      1.152      1.182         34        640: 100% 2/2 [00:00<00:00,  5.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.19it/s]\n",
            "                   all          7         16      0.928      0.271      0.762      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.41G     0.9971      1.077      1.094         44        640: 100% 2/2 [00:00<00:00,  5.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.05it/s]\n",
            "                   all          7         16      0.928      0.271      0.762      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.39G      1.023      1.229      1.175         25        640: 100% 2/2 [00:00<00:00,  5.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.19it/s]\n",
            "                   all          7         16      0.932      0.561      0.832      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.39G     0.9833      1.059      1.064         38        640: 100% 2/2 [00:00<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.84it/s]\n",
            "                   all          7         16      0.946      0.582       0.84       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.38G      1.016      1.179       1.11         37        640: 100% 2/2 [00:00<00:00,  5.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.26it/s]\n",
            "                   all          7         16      0.946      0.582       0.84       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.39G     0.9489      1.052      1.035         41        640: 100% 2/2 [00:00<00:00,  5.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.22it/s]\n",
            "                   all          7         16          1      0.282      0.807      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.39G       1.14      1.677      1.384         11        640: 100% 2/2 [00:00<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.33it/s]\n",
            "                   all          7         16      0.964      0.556       0.75      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50       2.4G     0.9658      1.086       1.17         27        640: 100% 2/2 [00:00<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.56it/s]\n",
            "                   all          7         16      0.964      0.556       0.75      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.38G     0.9466      1.063      1.093         34        640: 100% 2/2 [00:00<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.55it/s]\n",
            "                   all          7         16      0.958      0.433      0.821      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.41G     0.9496      1.071      1.055         49        640: 100% 2/2 [00:00<00:00,  4.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.20it/s]\n",
            "                   all          7         16       0.96      0.522      0.849      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.41G     0.8468     0.9622      1.007         24        640: 100% 2/2 [00:00<00:00,  5.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.49it/s]\n",
            "                   all          7         16       0.96      0.522      0.849      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.39G      1.022      1.068      1.086         24        640: 100% 2/2 [00:00<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.76it/s]\n",
            "                   all          7         16      0.952      0.557       0.94      0.734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.41G     0.9758      1.049      1.184         20        640: 100% 2/2 [00:00<00:00,  4.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 13.05it/s]\n",
            "                   all          7         16      0.947      0.583      0.945      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.37G     0.8755     0.9634      1.095         35        640: 100% 2/2 [00:00<00:00,  5.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.25it/s]\n",
            "                   all          7         16      0.947      0.583      0.945      0.722\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.36G     0.9103      1.108      1.119         18        640: 100% 2/2 [00:00<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.84it/s]\n",
            "                   all          7         16      0.919      0.695      0.945      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.37G     0.8767     0.9912      1.097         22        640: 100% 2/2 [00:00<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.20it/s]\n",
            "                   all          7         16      0.908      0.889      0.947      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.36G     0.8281      1.013      1.049         21        640: 100% 2/2 [00:00<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.44it/s]\n",
            "                   all          7         16      0.908      0.889      0.947      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.36G     0.8335      0.934      1.069         26        640: 100% 2/2 [00:00<00:00,  5.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.11it/s]\n",
            "                   all          7         16      0.896      0.917      0.949      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.36G     0.7695     0.9523      1.043         21        640: 100% 2/2 [00:00<00:00,  5.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.49it/s]\n",
            "                   all          7         16      0.896      0.917      0.949      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.36G     0.8561     0.9896      1.084         17        640: 100% 2/2 [00:00<00:00,  5.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 13.30it/s]\n",
            "                   all          7         16      0.878      0.917       0.96      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.36G     0.8174      1.159       1.08         20        640: 100% 2/2 [00:00<00:00,  6.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.93it/s]\n",
            "                   all          7         16      0.878      0.917       0.96      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.36G     0.7552      1.034      1.003         16        640: 100% 2/2 [00:00<00:00,  5.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.79it/s]\n",
            "                   all          7         16       0.92      0.961      0.973      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.36G      0.758     0.9249      1.006         21        640: 100% 2/2 [00:00<00:00,  6.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.99it/s]\n",
            "                   all          7         16       0.92      0.961      0.973      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.36G     0.8381      1.001      1.004         18        640: 100% 2/2 [00:00<00:00,  5.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.43it/s]\n",
            "                   all          7         16      0.941      0.952      0.973      0.743\n",
            "\n",
            "50 epochs completed in 0.018 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 12.95it/s]\n",
            "                   all          7         16      0.941      0.951      0.973      0.743\n",
            "                     1          5          9      0.899      0.995      0.929      0.685\n",
            "                    10          2          3      0.925          1      0.995      0.786\n",
            "                     5          3          4          1      0.858      0.995      0.759\n",
            "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "# Validate YOLOv8n\n",
        "!yolo train model=yolo11n.pt data=data.yaml epochs=50 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QW2hdQnJl10"
      },
      "source": [
        "# 4. Test Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR0b7K-OJmtg",
        "outputId": "d2c33198-24ef-435c-8b68-d3c32672ba1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\n",
            "image 1/3 /content/test/images/yt-qCY8_SQ93O8-0007_jpg.rf.1d6ea16eb98f0274befee9986fce52b2.jpg: 640x640 (no detections), 12.5ms\n",
            "image 2/3 /content/test/images/yt-qCY8_SQ93O8-0008_jpg.rf.8dc9c649994913355ca6870d33a7a46b.jpg: 640x640 (no detections), 8.7ms\n",
            "image 3/3 /content/test/images/yt-qCY8_SQ93O8-0027_jpg.rf.d0ea0f50cab56b117fc2ce784254567d.jpg: 640x640 (no detections), 8.6ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 13.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict11\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=/content/runs/detect/train/weights/best.pt conf=0.2 imgsz=640 source='/content/test/images/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCODJpDwJrYP"
      },
      "source": [
        "# 5. Test Video for Model Ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-GonltxVAVp",
        "outputId": "841b79e1-b48f-413a-b5b4-4aec4a7ca491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 986, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 559, in predict\n",
            "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\", line 190, in predict_cli\n",
            "    for _ in gen:  # sourcery skip: remove-empty-nested-block, noqa\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 36, in generator_context\n",
            "    response = gen.send(None)\n",
            "               ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\", line 233, in stream_inference\n",
            "    self.setup_source(source if source is not None else self.args.source)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\", line 205, in setup_source\n",
            "    self.dataset = load_inference_source(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\", line 214, in load_inference_source\n",
            "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\", line 341, in __init__\n",
            "    raise FileNotFoundError(f\"{p} does not exist\")\n",
            "FileNotFoundError: /content/drive/MyDrive/1A/DataTestENV2.mp4 does not exist\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=/content/runs/detect/train/weights/best.pt  conf=0.8 imgsz=640 source='/content/drive/MyDrive/1A/DataTestENV2.mp4'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}